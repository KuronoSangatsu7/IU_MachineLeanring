{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus assignement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Your submission should be the `.ipynb` file with your name,\n",
    "  like `FirstNameLastName.ipynb`. It should include the answers to the questions in\n",
    "  markdown cells.\n",
    "- You are expected to follow the best practices for code writing and model\n",
    "training. Poor coding style will be penalized.\n",
    "- You are allowed to discuss ideas with your peers, but no sharing of code.\n",
    "Plagiarism in the code will result in failing. If you use code from the\n",
    "internet, cite it. \n",
    "- Read each instruction carefully and provide complete answers to each question/task\n",
    "- You are allowed to use Keras or Pytorch \n",
    "\n",
    "> **_NOTE:_**  Write your email address in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j.totanji@innopolis.university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I- Open questions (3 points)\n",
    "\n",
    "Read [this article](https://link.springer.com/referenceworkentry/10.1007/978-0-387-73003-5_304) and answer the following questions:\n",
    "\n",
    "1. What is incremental learning?\n",
    "\n",
    "    - It is a Machine Learning paradigm that -opposite to traditional machine learning- does not assume the availabtility of a sufficient training set before the learning process, rather, the training examples appear over time. Per this paradigm, the learning process takes place whenever new examples emerge and adjusts what ahs been learned according to these new examples.\n",
    "\n",
    "2. Why is it important for us to create neural networks that would someday be able to learn incrementally?\n",
    "\n",
    "    - Since the original goal of the neural network approach is to create a computational system that could solve problems like a human brain, then we should try to simulate the way humans acquire knowledge, that is, incrementally over a period of time.\n",
    "    \n",
    "    - Additionally, if we want neural networks to solve real-world problems, then they have to be able to learn incrementally, because many real-world applications cannot match the ideal case of having a sufficient training set. Some examples of these problems are:\n",
    "\n",
    "        - Applications where the target concepts change over time (Robotics, Intelligent Agent).\n",
    "        - Applications where the “sufficient training sets” are too big (Content based image retrieval, Face recognition).\n",
    "        - Applications where the training examples are obtained over time (Visual object tracking, Software project estimation).\n",
    "\n",
    "3. What is catastrophic forgetting?\n",
    "\n",
    "     - Catastrophic Forgetting is the tendency of an artificial neural network to abruptly and drastically forget previously learned information upon learning new information. Specifically, catastrophic forgetting occurs when a network is trained sequentially on multiple tasks because the weights in the network that are important for task A are changed to meet the objectives of task B. And is the main limitation of neural networks being unable to build knowledge incrementally over large periods of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II- Train simple CNN model for digit classification (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "- Load MNIST dataset and split it in **Tr**ainning (`Tr`) and **Te**ting set (`Te`), 80% and 20% respectively.\n",
    "- Train a simple CNN for digit classification on the training set. \n",
    "- After fine tuning your CNN, evaluate the `overall` and the `class-wise` performances on `Te`. \n",
    ">**NOTE:** For the class-wise performance, you should plot (e.g., bar plots) the performance of your model on each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f546e38f130>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f546ef9f910>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the MNIST dataset and splitting into training and testing sets\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Grayscale(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_data = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "test_data = datasets.MNIST(root='data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Added together both datasets instead of splitting only one\n",
    "data = ConcatDataset([train_data, test_data])\n",
    "\n",
    "# 80 20 split\n",
    "train_set, test_set = torch.utils.data.random_split(data, [56000, 14000])\n",
    "\n",
    "loaders = {\n",
    "    'train' : DataLoader(train_set, batch_size=100, shuffle=True, num_workers=1),\n",
    "    \n",
    "    'test'  : DataLoader(test_set, batch_size=100, shuffle=True, num_workers=1),\n",
    "}\n",
    "\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/560], Loss: 0.0714\n",
      "Epoch [1/10], Step [200/560], Loss: 0.1775\n",
      "Epoch [1/10], Step [300/560], Loss: 0.0708\n",
      "Epoch [1/10], Step [400/560], Loss: 0.1117\n",
      "Epoch [1/10], Step [500/560], Loss: 0.0413\n",
      "Epoch [2/10], Step [100/560], Loss: 0.0249\n",
      "Epoch [2/10], Step [200/560], Loss: 0.1250\n",
      "Epoch [2/10], Step [300/560], Loss: 0.0282\n",
      "Epoch [2/10], Step [400/560], Loss: 0.0546\n",
      "Epoch [2/10], Step [500/560], Loss: 0.0290\n",
      "Epoch [3/10], Step [100/560], Loss: 0.0212\n",
      "Epoch [3/10], Step [200/560], Loss: 0.0705\n",
      "Epoch [3/10], Step [300/560], Loss: 0.0127\n",
      "Epoch [3/10], Step [400/560], Loss: 0.0122\n",
      "Epoch [3/10], Step [500/560], Loss: 0.0091\n",
      "Epoch [4/10], Step [100/560], Loss: 0.0826\n",
      "Epoch [4/10], Step [200/560], Loss: 0.0442\n",
      "Epoch [4/10], Step [300/560], Loss: 0.0363\n",
      "Epoch [4/10], Step [400/560], Loss: 0.0887\n",
      "Epoch [4/10], Step [500/560], Loss: 0.1079\n",
      "Epoch [5/10], Step [100/560], Loss: 0.0091\n",
      "Epoch [5/10], Step [200/560], Loss: 0.0155\n",
      "Epoch [5/10], Step [300/560], Loss: 0.0277\n",
      "Epoch [5/10], Step [400/560], Loss: 0.0735\n",
      "Epoch [5/10], Step [500/560], Loss: 0.1096\n",
      "Epoch [6/10], Step [100/560], Loss: 0.0077\n",
      "Epoch [6/10], Step [200/560], Loss: 0.0340\n",
      "Epoch [6/10], Step [300/560], Loss: 0.0647\n",
      "Epoch [6/10], Step [400/560], Loss: 0.1644\n",
      "Epoch [6/10], Step [500/560], Loss: 0.0880\n",
      "Epoch [7/10], Step [100/560], Loss: 0.0628\n",
      "Epoch [7/10], Step [200/560], Loss: 0.0011\n",
      "Epoch [7/10], Step [300/560], Loss: 0.0023\n",
      "Epoch [7/10], Step [400/560], Loss: 0.0257\n",
      "Epoch [7/10], Step [500/560], Loss: 0.2357\n",
      "Epoch [8/10], Step [100/560], Loss: 0.0391\n",
      "Epoch [8/10], Step [200/560], Loss: 0.1209\n",
      "Epoch [8/10], Step [300/560], Loss: 0.0414\n",
      "Epoch [8/10], Step [400/560], Loss: 0.0166\n",
      "Epoch [8/10], Step [500/560], Loss: 0.0759\n",
      "Epoch [9/10], Step [100/560], Loss: 0.0492\n",
      "Epoch [9/10], Step [200/560], Loss: 0.0906\n",
      "Epoch [9/10], Step [300/560], Loss: 0.0886\n",
      "Epoch [9/10], Step [400/560], Loss: 0.0274\n",
      "Epoch [9/10], Step [500/560], Loss: 0.0641\n",
      "Epoch [10/10], Step [100/560], Loss: 0.0041\n",
      "Epoch [10/10], Step [200/560], Loss: 0.0670\n",
      "Epoch [10/10], Step [300/560], Loss: 0.1167\n",
      "Epoch [10/10], Step [400/560], Loss: 0.0323\n",
      "Epoch [10/10], Step [500/560], Loss: 0.1225\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "num_epochs = 10\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)  \n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "\n",
    "    cnn.train()\n",
    "\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "            output = cnn(images)[0]\n",
    "            loss = loss_func(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model and measuring preformance\n",
    "\n",
    "classes = [i for i in range(10)]\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        class_wise_acc = [(0, 0) for c in classes]\n",
    "\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            overall_acc = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "\n",
    "            for c in classes:\n",
    "                class_wise_acc[c] = (class_wise_acc[c][0] + ((pred_y == labels) * (labels == c)).sum().item(),\n",
    "                                     class_wise_acc[c][1] + float((labels == c).sum().item()))\n",
    "\n",
    "            pass\n",
    "    \n",
    "    class_wise_acc = [num/denom for (num, denom) in class_wise_acc]\n",
    "\n",
    "    return overall_acc, class_wise_acc\n",
    "\n",
    "overall_accuracy, class_wise_accuracy = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall test Accuracy of the model on the test set: 0.97\n",
      "The class-wise accuracy of the model on the test set:\n",
      "Class: 0 | Accuracy: 0.9687045123726347\n",
      "Class: 1 | Accuracy: 0.9936427209154481\n",
      "Class: 2 | Accuracy: 0.9733333333333334\n",
      "Class: 3 | Accuracy: 0.9781690140845071\n",
      "Class: 4 | Accuracy: 0.9875640087783467\n",
      "Class: 5 | Accuracy: 0.9736842105263158\n",
      "Class: 6 | Accuracy: 0.9949238578680203\n",
      "Class: 7 | Accuracy: 0.9872225958305313\n",
      "Class: 8 | Accuracy: 0.966467958271237\n",
      "Class: 9 | Accuracy: 0.9608411892675852\n"
     ]
    }
   ],
   "source": [
    "# Performance on Test Set\n",
    "print('The overall test Accuracy of the model on the test set: %.2f' % overall_accuracy)\n",
    "print('The class-wise accuracy of the model on the test set:')\n",
    "\n",
    "for i, acc in enumerate(class_wise_accuracy):\n",
    "    print(f'Class: {i} | Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting class-wise accuracy\n",
    "\n",
    "y_ticks = [i for i in np.arange(0.90, 1.01, 0.01)]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(classes)\n",
    "plt.yticks(y_ticks)\n",
    "plt.ylim(0.90,1.00)\n",
    "plt.bar(classes, class_wise_accuracy, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III- Create different tasks from the MNIST dataset (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `Tr` into 3 datasets (tasks) according to the following distribution.\n",
    "\n",
    "- Task 1 contains digits of classes 0, 1, and 2. \n",
    "- Task 2 contains classes 3, 4, and 5. \n",
    "- Task 3 contains classes 6, 7, 8, and 9.\n",
    " \n",
    "*The following picture showcases the general scheme*\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1vdDgdN9BGQ2Jl3Yg4YiPvfb5fcAeJZJ-' style=\"width:500px;\"> \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data according to labels\n",
    "\n",
    "labelled_data = {}\n",
    "\n",
    "for i in range(0, len(train_set)):\n",
    "    target = train_set[i][1]\n",
    "\n",
    "    if not target in labelled_data:\n",
    "        labelled_data[target] = []\n",
    "        labelled_data[target].append(train_set[i])\n",
    "    \n",
    "    else:\n",
    "        labelled_data[target].append(train_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding lengths of the 3 partial datasets:\n",
      "Set 1: 17385 Items\n",
      "Set 2: 16179 Items\n",
      "Set 3: 22436 Items\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into 3 subsets\n",
    "\n",
    "train_set_1 = []\n",
    "for i in range(0, 3):\n",
    "    train_set_1 += labelled_data[i]\n",
    "\n",
    "train_set_2 = []\n",
    "for i in range(3, 6):\n",
    "    train_set_2 += labelled_data[i]\n",
    "\n",
    "train_set_3 = []\n",
    "for i in range(6, 10):\n",
    "    train_set_3 += labelled_data[i]\n",
    "\n",
    "print(\"Corresponding lengths of the 3 partial datasets:\")\n",
    "\n",
    "print(f\"Set 1: {len(train_set_1)} Items\\nSet 2: {len(train_set_2)} Items\\nSet 3: {len(train_set_3)} Items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_1': <torch.utils.data.dataloader.DataLoader at 0x7f546e405160>,\n",
       " 'train_2': <torch.utils.data.dataloader.DataLoader at 0x7f546e395a00>,\n",
       " 'train_3': <torch.utils.data.dataloader.DataLoader at 0x7f5534064520>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f5534064760>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feeding the data into DataLoaders\n",
    "\n",
    "loaders = {\n",
    "    'train_1' : DataLoader(train_set_1, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'train_2' : DataLoader(train_set_2, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'train_3' : DataLoader(train_set_3, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'test' : DataLoader(test_set, batch_size=100, shuffle=True, num_workers=1)\n",
    "}\n",
    "\n",
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV- Class-incremental learning implementation (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the different tasks (datasets) you created previously, implement a CNN for class incremental learning according to the following instructions. \n",
    "- The neural network architecture is not given, choose and tune your architecture following DNNs best practices. Similarly for the training no hyperparameters are given to you, you should choose them and justify your choice. Hyperparameter tuning is not mandatory but doing it would be a plus.\n",
    "- Your network should have shared feature extractor (shared layers) part and separate classifier head (e.g., fully connected layers) for each task (see the figure below).\n",
    "- When training on a new task, the shared layers part will get updated along with the head of the current task. \n",
    "- After training each task (Task 1 & 2), evaluate (and plot) the performances of the current and the previous tasks on `Te`.\n",
    "    - Once the training on the last task is complete, test the model on `Te` and compare the performance of the network with the CNN trained in II, i.e., plot the `overall` and the `class-wise` performances for classical learning and incremental learning.\n",
    "\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1HfwcMP7jGoJnYEMu7jDqloQNogEZsjrJ'  style=\"width:250px;\"> \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V- Report (2 points)\n",
    "Write a short report on the results you got and what you learned from this activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. The open questions:\n",
    "    - The article was an interesting read about a problem that we -as humans- are trying to tackle at the moment. I knew almost nothing about incremental learning but after reading the article I was a little scared of what we might be able to create (emphasis on \"create\") with such technologies :)\n",
    "\n",
    "II. Train simple CNN model for image calssification:\n",
    "- Data Preprocessing and Augmentation:\n",
    "    - I first loaded the MNIST Dataset from Pytorch. The default Train and Test splits were not the required 80/20 ratio. I decided to merge both the datasets into one larger set, and then randomly split that into 80/20 training and testing sets.\n",
    "\n",
    "    - Not a whole lot went into Agumentation since the MNIST set is quite \"clean\", so to speak. And also because the testing was going to happen on data from the same domain which doesnt require the model to handle any complex cases (e.g. real-life numbers, etc.). All I did was Grayscale the images to get rid of any color noise, and then transform them into a Tensor and Normalize them for faster processing.\n",
    "\n",
    "- The CNN Model:\n",
    "    - The model I used here was introduced in Lab 9 of our course to solve the same problem and achieved high accuracy.\n",
    "\n",
    "    - The model itself is quite simple, consisting of one Convolutional layer which uses a ReLu activation function, followed by a fully-connected layer with 10 outputs, each output corresponding to one of our target classes.\n",
    "\n",
    "- Training and Testing:\n",
    "    - Trained the model for 10 epochs and used CrossEntropyLoss to calculate the loss.\n",
    "\n",
    "    - For testing, I used the final model to make predictions on my test dataset from earlier.\n",
    "\n",
    "    - Calculating the accuracy was pretty straightforward, I simply divided the number of correct prediction over the total number of datapoints. For class-wise accuracy, the same technique was used, but using a list to keep track of the number of correct predicitons, and total number of datapoints for each class individually.\n",
    "\n",
    "- Even though this part of the task did not include a lot of new things. It was actually very beneficial for me to implement as I employed all the knowledge and experience from the mistakes that I made in the previous assignment to go through it pretty smoothly :)\n",
    "\n",
    "III. Create different tasks from the MNIST Dataset:\n",
    "\n",
    "- I first used dictionary to group datapoints which have the same target into separate lists.\n",
    "\n",
    "- Then, I concatenated the lists of the corresponding groups ([0, 2], [3, 5], [6, 9]) to create new datasets.\n",
    "\n",
    "- Finally, I fed the 3 datasets along with the test set from the previous task into a DataLoader to prepare them for Incremental Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- Incremental Learning: \n",
    "    - https://link.springer.com/referenceworkentry/10.1007/978-0-387-73003-5_304\n",
    "<br></br>\n",
    "\n",
    "- Catastrophic Forgetting:\n",
    "    - https://medium.com/dataseries/some-ideas-about-catastrophic-forgetting-in-neural-networks-34b2c95c9d13\n",
    "    - https://en.wikipedia.org/wiki/Catastrophic_interference\n",
    "<br></br>\n",
    "\n",
    "- Concatenating Datasets:\n",
    "\n",
    "    - https://discuss.pytorch.org/t/combine-train-and-test-data/24004\n",
    "<br></br>\n",
    "\n",
    "- Measuring class-wise accuracy:\n",
    "\n",
    "    - https://stackoverflow.com/questions/62958248/calculate-accuracy-for-each-class-using-cnn-and-pytorch\n",
    "<br></br>\n",
    "\n",
    "- The CNN model, training, and testing:\n",
    "\n",
    "    - Intro to ML Course, Lab 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
